{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31ac3376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ad4bc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_scalar(indep_X, dep_Y):    \n",
    "    # Splitting the dataset into the Training set and Test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size=0.25, random_state=0)\n",
    "    # Feature Scaling\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def lcadim(X_train, y_train, n):\n",
    "    # Applying LDA\n",
    "    lda = LDA(n_components=n)\n",
    "    X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "    explained_variance = lda.explained_variance_ratio_\n",
    "    return lda, X_train_lda, explained_variance\n",
    "\n",
    "def cm_prediction(classifier, X_test, y_test):\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    return classifier, cm, accuracy, report, X_test, y_test\n",
    "\n",
    "def logistic(X_train, y_train, X_test, y_test):\n",
    "    # Fitting logistic regression to the Training set\n",
    "    classifier = LogisticRegression(random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    classifier, cm, accuracy, report, X_test, y_test = cm_prediction(classifier, X_test, y_test)\n",
    "    return classifier, cm, accuracy, report, X_test, y_test\n",
    "\n",
    "def svm_linear(X_train, y_train, X_test, y_test):\n",
    "    classifier = SVC(kernel='linear', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    classifier, cm, accuracy, report, X_test, y_test = cm_prediction(classifier, X_test, y_test)\n",
    "    return classifier, cm, accuracy, report, X_test, y_test\n",
    "\n",
    "def svm_rbf(X_train, y_train, X_test, y_test):\n",
    "    classifier = SVC(kernel='rbf', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    classifier, cm, accuracy, report, X_test, y_test = cm_prediction(classifier, X_test, y_test)\n",
    "    return classifier, cm, accuracy, report, X_test, y_test\n",
    "\n",
    "def naive_bayes(X_train, y_train, X_test, y_test):\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    classifier, cm, accuracy, report, X_test, y_test = cm_prediction(classifier, X_test, y_test)\n",
    "    return classifier, cm, accuracy, report, X_test, y_test\n",
    "\n",
    "def knn(X_train, y_train, X_test, y_test):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    classifier, cm, accuracy, report, X_test, y_test = cm_prediction(classifier, X_test, y_test)\n",
    "    return classifier, cm, accuracy, report, X_test, y_test\n",
    "\n",
    "def decision_tree(X_train, y_train, X_test, y_test):\n",
    "    classifier = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    classifier, cm, accuracy, report, X_test, y_test = cm_prediction(classifier, X_test, y_test)\n",
    "    return classifier, cm, accuracy, report, X_test, y_test\n",
    "\n",
    "def random_forest(X_train, y_train, X_test, y_test):\n",
    "    classifier = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    classifier, cm, accuracy, report, X_test, y_test = cm_prediction(classifier, X_test, y_test)\n",
    "    return classifier, cm, accuracy, report, X_test, y_test\n",
    "\n",
    "def lda_result(acclog, accsvml, accsvmrbf, accnavie, accknn, accdes, accrf):\n",
    "    dataframe = pd.DataFrame(index=['LDA_2'], columns=['Logistic', 'SVM_linear', 'SVM_rbf', 'Naive Bayes', 'KNN', 'Decision Tree', 'Random Forest'])\n",
    "    for number, idx in enumerate(dataframe.index):\n",
    "        dataframe['Logistic'][idx] = acclog[number]\n",
    "        dataframe['SVM_linear'][idx] = accsvml[number]\n",
    "        dataframe['SVM_rbf'][idx] = accsvmrbf[number]\n",
    "        dataframe['Naive Bayes'][idx] = accnavie[number]\n",
    "        dataframe['KNN'][idx] = accknn[number]\n",
    "        dataframe['Decision Tree'][idx] = accdes[number]\n",
    "        dataframe['Random Forest'][idx] = accrf[number]\n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccb88cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "      <th>SVM_linear</th>\n",
       "      <th>SVM_rbf</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LDA_2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Logistic SVM_linear SVM_rbf Naive Bayes  KNN Decision Tree Random Forest\n",
       "LDA_2      1.0        1.0     1.0         1.0  1.0           1.0           1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_csv(\"Wine.csv\")\n",
    "indep_X = dataset.iloc[:, 0:13].values\n",
    "dep_Y = dataset.iloc[:, 13].values\n",
    "\n",
    "# Perform LDA\n",
    "lda, X_train_lda, explained_variance = lcadim(indep_X, dep_Y, 2)\n",
    "\n",
    "# Initialize lists to store accuracies\n",
    "acclog = []\n",
    "accsvml = []\n",
    "accsvmrbf = []\n",
    "accnavie = []\n",
    "accknn = []\n",
    "accdes = []\n",
    "accrf = []\n",
    "\n",
    "# Split data, train classifiers, and evaluate\n",
    "X_train, X_test, y_train, y_test = split_scalar(X_train_lda, dep_Y)\n",
    "\n",
    "classifier, cm, accuracy, report, X_test, y_test = logistic(X_train, y_train, X_test, y_test)\n",
    "acclog.append(accuracy)\n",
    "\n",
    "classifier, cm, accuracy, report, X_test, y_test = svm_linear(X_train, y_train, X_test, y_test)\n",
    "accsvml.append(accuracy)\n",
    "\n",
    "classifier, cm, accuracy, report, X_test, y_test = svm_rbf(X_train, y_train, X_test, y_test)\n",
    "accsvmrbf.append(accuracy)\n",
    "\n",
    "classifier, cm, accuracy, report, X_test, y_test = naive_bayes(X_train, y_train, X_test, y_test)\n",
    "accnavie.append(accuracy)\n",
    "\n",
    "classifier, cm, accuracy, report, X_test, y_test = knn(X_train, y_train, X_test, y_test)\n",
    "accknn.append(accuracy)\n",
    "\n",
    "classifier, cm, accuracy, report, X_test, y_test = decision_tree(X_train, y_train, X_test, y_test)\n",
    "accdes.append(accuracy)\n",
    "\n",
    "classifier, cm, accuracy, report, X_test, y_test = random_forest(X_train, y_train, X_test, y_test)\n",
    "accrf.append(accuracy)\n",
    "\n",
    "# Create result dataframe\n",
    "result = lda_result(acclog, accsvml, accsvmrbf, accnavie, accknn, accdes, accrf)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375252ba",
   "metadata": {},
   "source": [
    "#1 result\n",
    "          Logistic\tSVM_linear\tSVM_rbf\t   Naive Bayes\tKNN\t     Decision Tree\tRandom Forest\n",
    "LDA_1\t0.866667\t0.888889\t0.866667\t0.866667\t0.866667\t0.911111\t0.88888911"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f17e6a",
   "metadata": {},
   "source": [
    "#2result\n",
    "      Logistic\tSVM_linear\tSVM_rbf \tNaive Bayes  \tKNN\t    Decision Tree\tRandom Forest\n",
    "LDA_2\t1.0\t        1.0\t      1.0\t        1.0\t          1.0\t      1.0\t        1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc8520de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd model found ok accuracy above 100%, Highest accracy in all model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
